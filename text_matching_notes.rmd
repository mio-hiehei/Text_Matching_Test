---
title: 'Notes on Text Matching'
author: 'Mio Hie-Hei'
date: '`r Sys.Date()`'
output: html_document
---


## Article ADjusting for Confounding with Text matching

- Problem with Text matching: finding units of analysis that are similar on all dimensions (the number of which in DFMs can be very fucking high)

Contribution of Authors:

1. Framework to use text to address confounding in obs studies.
2. general text-matching adjustment strategy balancing on low-dimensional density estimate of data.
3. topical inverse regression matching to match on a jointly estimated propensity for treatment and density estimate.

This approach requires but facilitates human validation of matching process.
```{r load packages}

library(optimx)
library(MASS)

```



Let's start with some test data.

```{r generate test data}

source("functions.R")

data <- create_test_data(ncol = 400, nrow = 100)
dfm <- data$df
vocab <- gen_random_words(n = ncol(dfm))
colnames(dfm)  <- vocab
treatment <- data$treatment
y <- data$y
k <- 15

x_2bm <- gen_stm_data(k = k, nrow = nrow(dfm))

```

What is the first step? We have a lot of observational data. Now we want to split our dataset in two groups: into a treatment and a control group. We have a very large dimensionality, hence: many columns for fewer rows.

We want to create two subsets of our data that are as equal as possible with regards to all the columns except for our $y$-column.

What do we do? Common algorithms try to match using as much data as possible, but with this approach is going to be hard to match all of the columns because there are too many dimensions and it is unlikely that we will find matches for all. This is where Roberts et al. come into play: We apply TIRM:

1. estimate structural topic model including the treatment variable as a content covariate.
2. extract each document's (row's) topics calculated as though treated (part of $g(W)$).
3. Extract each document's (row's) projection onto the treatment variable (part of $g(W)$).
4. Use a low dimensional matching method to match on $g(W)$ and estimate treatment effects using the matched sample.


Let's skip some steps and get to the matching.

```{r ps matching}

prob_score <-  est_prop_score(X=x_2bm, t=treatment, nsim = 1000)
mat <- cbind(prob_score, treatment, y)


ind_control <- which(mat[, "treatment"] == 0)

matched_control <- vector()

while(i <= nrow(mat)){

  if (mat[i, "treatment"] == 1){
    
     matched_control[i] <- mat[ind_control[which.min(abs(mat[ind_control, "prob_score"] - mat[i, "prob_score"]))],"prob_score"]
  } else {
    
    matched_control[i] <- NA
    
  }
  cat(matched_control[i], "\n") 
  i <- i + 1

  
}

foundmatch_control <- matched_control[!(is.na(matched_control))]
foundmatch_control_index <- which(!(is.na(matched_control)))


length(foundmatch_control) == length(which(mat[, "treatment" ] == 1))

matched_df <- mat[c(which(mat[, "treatment" ] == 1), foundmatch_control),]

yt <- mean(matched_df[which(matched_df[,"treatment"] == 1), "y"])

yc <- mean(matched_df[which(matched_df[,"treatment"] == 0), "y"])

table(matched_df[,"treatment"])

yt - yc


## Robustness:
### how many C are used?
length(unique(foundmatch_control)) / nrow(mat[which(mat[,"treatment"] == 0),])

### Distribution of prosp scores between T and new C
hist()
matched_df[which(matched_df[,"treatment"] == 0), "prob_score"]
```
